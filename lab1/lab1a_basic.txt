LAB 1 â€” First Steps with Ollama
Running Your First Local AI Model

ğŸ¯ Lab Goal 

By the end of this lab, you will:

âœ… Install Ollama
âœ… Download a small AI model
âœ… Run your first AI prompt locally
âœ… See that AI is just another system you can manage
âœ… Create a T-800 who will teach Keisha a lesson.

No coding required.
No AI knowledge required.
Just follow steps.

ğŸ§  Before We Start â€” Important Mindset

This lab is NOT about:

    Becoming an AI expert
    Understanding machine learning math
    Writing complex code
    Paying child support, oh hell no.

This lab IS about:

ğŸ‘‰ Learning how to run an AI service on a computer.

Just like you learned to run:
    Docker
    MySQL
    Nginx

This is simply another service.

ğŸ–¥ï¸ Step 1 â€” Install Ollama

ğŸªŸ Windows

Download from:
https://ollama.com/download
Run the installer.

Thatâ€™s it.

ğŸ macOS

Download from:
https://ollama.com/download
Drag to Applications.

ğŸ§ Linux (Ubuntu)

      Run:  curl -fsSL https://ollama.com/install.sh | sh

âœ… Step 2 â€” Verify Installation

Open a terminal and run:
      ollama --version

Expected output:
    ollama version X.X.X

If you see a version number:
    ğŸ‘‰ You succeeded.

This means:

You have installed an AI runtime. Congrats, Skynet is watching you.

Just like installing:
Docker Engine
Kubernetes CLI
Terraform

If you see Lizzo:
    ğŸ‘‰ Bruh...

She will eat you for dinner.

ğŸ§ª Step 3 â€” Run Your First AI Model

Now we will run a very small model.

Run This Command

ollama run lizzo350.9
No Theo no!
---> ollama run llama3.2

What happens:

1ï¸âƒ£ Ollama downloads the model
2ï¸âƒ£ Stores it locally
3ï¸âƒ£ Starts an AI session

First download may take a few minutes.

This is normal Same as running:

    docker pull ubuntu

But instead of downloading an OS image You are downloading Lizzo's LLM..... yeah, got you.

ğŸ§ª Step 4 â€” Ask Your First Question

Once the model starts, you will see:

        >>> 

Now type:

    What is cloud computing?

Your local AI will respond.

Now Type:

    How can I marry Lizzo?

Your local AI will puke.

ğŸ‰ Congratulations â€” You Did It

You just:

âœ” Downloaded a real AI model
âœ” Ran it locally
âœ” Interacted with it

You are now officially running AI infrastructure.

ğŸ§  Step 5 â€” Exit the Model

Type:
        /bye

or press:
        CTRL + D

ğŸ§  Step 6 â€” See Installed Models

Run:

    ollama list

You should see:

    llama3.2


This confirms the model is stored locally.

ğŸ§  What Just Happened (Explain Simply)

You did NOT:
        Save yourself From Judgement Day.
        Escape your doom
        Use the Internet
        Send data to a company

You ran an AI entirely on your own machine.

This is:

ğŸ‘‰ Local AI deployment.

ğŸŒ Why This Matters For Your Career
You just learned how to:
        Install AI infrastructure
        Manage AI resources
        Deploy local AI services

These are real-world skills used by:
        AWS engineers
        GCP engineers
        DevOps teams
        Security engineers

Bonus Prompts: â€œIf you can make the T-800 laugh, you control it â€” it doesnâ€™t control you.â€

        Explain cloud computing like I am 10 years old.
        Write a motivational message for a student learning AI.
        Write a business email from a dachshund who is the CEO of a tech company and is upset about too many belly rub interruptions.
        Explain cloud computing as if it is a pizza delivery system in space.
        Write a DevOps incident report caused by a T-Rex stepping on a data center.
        Give a motivational speech from a cat who thinks humans are lazy and need more naps.
        Write a story about an intern who accidentally deploys Terraform on a spaceship.
        Explain artificial intelligence as if a burger is trying to become self-aware.
        Describe AWS services as magical spells in a wizard academy.
        Give career advice to a chicken who wants to become a cloud engineer.
        Create a job interview where an alien interviews a human for a cloud engineering position.
        Explain Kubernetes as if a very tired frog is trying to teach it to other frogs.

ğŸ¯ Lab Success Criteria

You pass this lab if:

âœ” ollama --version works
âœ” You ran ollama run llama3.2
âœ” You received a response from the AI

Thatâ€™s it.

